# Sweet summer child score
_Risk assessment quiz for automation and ML_

## Run the quiz in python
**Requirements**   
- Python3+ installed
- Can use a terminal to clone a repo and navigate around directories (native or your own client) 

**Instructions**  
- Open your terminal 
- Clone https://github.com/summerscope/summerchildpy locally 

`$ git clone git@github.com:summerscope/summerchildpy.git`
- CD to inside the repo (wherever you cloned it locally) 
- Run script with python 

`$ python3 summerchild.py`
- Questions should appear now on your terminal

## Run the quiz in google colab

**Requirements**   
- Google account

**Instructions**  
- Navigate to [https://colab.research.google.com/drive/1LG__62nsr_KuNzOwKMULy3GbV9KFCM1Q?usp=sharing](https://colab.research.google.com/drive/1LG__62nsr_KuNzOwKMULy3GbV9KFCM1Q?usp=sharing)  
- Press the play button on the first cell
- Questions should appear


## Run the quiz in R

See separate R repo with instructions at:  
[https://github.com/summerscope/summerchildr](https://github.com/summerscope/summerchildr)  

---------------------------------------

### Overview
Sweet Summer Child Score (SSCS) is a scoring mechanism for latent risk. It will help you quickly and efficiently scan for the possibility of harm to people and communities by a socio-technical system. Note that harms to animals and the environment are not considered.   

SSCS takes a step back away from the specifics of your technology and looks at environmental, systems and human factors. It's intended to be used at the ideation part of your process, to critique product ideas or compare competing features. But SSCS can also be used post-hoc to critique an existing system, or propose approaches to harm mitigation.

### How long does it take?
If you're familiar with the automated decision system it should take 8-10 minutes to complete. Respond with your gut, don't overthink it too much.

### Critiquing proposals/ideas
You can absolutely use the score to critique ideas that aren't developed yet. You need to have sufficiently sketched it out and have the rough shape & feature set of the proposal or idea.

### How is it calculated?
You start with a score of 99 (the highest score possible, to acknowledge the impossibility of building and deploying something perfectly fair, or perfectly accurate and bug-free). As you answer questions, points are deducted from your score. The sections are worth roughly 1/3 each. The multiplier score will reduce the overall cost of points deductions in-line with the scope of your system overall.

### Who can use it?
This is designed for use by data scientists, product managers, and other technologists. However it's simple enough that end-users, journalists and auditors can use it as a form of socio-technical critique. This score is model and stack agnostic, so you don't need to see 'under-the-hood' to use it.

### How should you use it?
This is a qualitative assessment and relies on you to complete it honestly. There's no point if you're just going to give yourself the best score! Without discussing first, have multiple people in your team complete the quiz. How close were your scores? Which areas did you agree and disagree? Discuss and attempt to resolve the differences, especially where there are answers that are 2 or more steps away from each other.

### Why don't we scan for minority identities?
We focus on the disadvantages usually experienced by these populations rather than the demographics of disadvantage. We don't want to contribute to the conflation of minority identities and harm.
